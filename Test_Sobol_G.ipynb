{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tese case: Sobl's G*-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import numba as nb\n",
    "import itertools\n",
    "\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Sobol's G*-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(values, delta, alpha, a):\n",
    "    \"\"\"Sobol G*-function.\n",
    "\n",
    "    .. [1] Saltelli, A., Annoni, P., Azzini, I., Campolongo, F., Ratto, M., \n",
    "           Tarantola, S., 2010. Variance based sensitivity analysis of model \n",
    "           output. Design and estimator for the total sensitivity index. \n",
    "           Computer Physics Communications 181, 259â€“270. \n",
    "           https://doi.org/10.1016/j.cpc.2009.09.018\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    values : numpy.ndarray\n",
    "        input variables\n",
    "    delta : numpy.ndarray\n",
    "        parameter values\n",
    "    alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    a : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Y : Result of G*-function\n",
    "    \"\"\"\n",
    "    # Check the dimension of the input\n",
    "    if (values.shape[1] != delta.shape[0]):\n",
    "        raise ValueError(\"The dimension of inputs is not consistent\")\n",
    "    elif (values.shape[1] != alpha.shape[0]):\n",
    "        raise ValueError(\"The dimension of inputs is not consistent\")\n",
    "    elif (values.shape[1] != a.shape[0]):\n",
    "        raise ValueError(\"The dimension of inputs is not consistent\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if type(values) != np.ndarray:\n",
    "        raise TypeError(\"The argument `values` must be a numpy ndarray\")\n",
    "\n",
    "    ltz = values < 0\n",
    "    gto = values > 1\n",
    "\n",
    "    if ltz.any() == True:\n",
    "        raise ValueError(\"Sobol G function called with values less than zero\")\n",
    "    elif gto.any() == True:\n",
    "        raise ValueError(\"Sobol G function called with values greater than one\")\n",
    "        \n",
    "    gi = ((1 + alpha) * np.power(np.abs(2 * (values + delta - np.modf(values + delta)[1]) - 1), alpha) + a) / (1 + a)\n",
    "\n",
    "    return np.prod(gi, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definde analytical parameter sensitivity indices for individual system model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_first_order_variance(alpha, a):\n",
    "    \"\"\"Compute the partial first order variance of Vi\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    a : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Vi : The partial first order variance, which has the same size of alpah and a\n",
    "    \"\"\"\n",
    "    return np.power(alpha, 2) / ((1 + 2 * alpha) * np.power((1 + a), 2))\n",
    "\n",
    "def partial_total_order_variance(alpha, a):\n",
    "    \"\"\"Compute the partial total order variance of Vi\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    a : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    VTi : The partial total order variance, which has the same size of alpah and a\n",
    "    \"\"\"\n",
    "    pv = partial_first_order_variance(alpha, a)\n",
    "    product_pv = np.product(1 + partial_first_order_variance(alpha, a), axis=0)\n",
    "    return pv * np.divide(product_pv, 1 + pv.T)\n",
    "\n",
    "def single_model_total_variance(alpha, a):\n",
    "    \"\"\"Compute the variance for a single system model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    a : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    V : The variance of the ouput, which is a scalar value \n",
    "    \"\"\"\n",
    "    return np.add(-1, np.product(1 + partial_first_order_variance(alpha, a), axis=0))\n",
    "\n",
    "def first_order_parameter_sensitivity_index(alpha, a):\n",
    "    \"\"\"Compute the first order parameter sensitivity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    a : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Si: The first order parameter sensitivity index, which has the same size of alpah and a \n",
    "    \"\"\"\n",
    "    return np.divide(partial_first_order_variance(alpha, a), single_model_total_variance(alpha, a))\n",
    "\n",
    "def total_parameter_sensitivity_index(alpha, a):\n",
    "    \"\"\"Compute the total parameter sensitivity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    a : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    STi: The total parameter sensitivity index, which has the same size of alpah and a \n",
    "    \"\"\"\n",
    "    tv = single_model_total_variance(alpha, a)\n",
    "    return np.divide(partial_total_order_variance(alpha, a), tv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definde analytical process sensitivity indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_model_total_variance(Alpha, A):\n",
    "    \"\"\"Compute variance of the output considering mutiple system models\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    A : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    V : The variance of the ouput, which is a scalar value \n",
    "    \"\"\"\n",
    "    N = Alpha.shape[0]                    # Number of the system models\n",
    "    model_weight = 1.0 / N                # Model weight for each system models\n",
    "    return sum(single_model_total_variance(Alpha[i, :], A[i, :]) * model_weight for i in range(N))\n",
    "    \n",
    "def first_order_process_sensitivity_index(alpha, a):\n",
    "    \"\"\"Compute first-order process sensitivity index considering mutiple system models\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    a : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    V : first-order process sensitivity index, which has the same size of alpah and a \n",
    "    \"\"\"\n",
    "    N = alpha.shape[0]                    # Number of processes\n",
    "    return [np.mean(partial_first_order_variance(alpha[i, :], a[i, :])) / multi_model_total_variance(Alpha, A) for i in range(N)]\n",
    "\n",
    "def total_order_process_sensitivity_index(Alpha, A):\n",
    "    \"\"\"Compute total process sensitivity index considering mutiple system models\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Alpha : numpy.ndarray\n",
    "        parameter values\n",
    "    A : numpy.ndarray\n",
    "        parameter values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    V : first-order process sensitivity index, which has the same size of Alpha.shape[1]\n",
    "    \"\"\"\n",
    "    N = Alpha.shape[0]                    # Number of the system models\n",
    "    model_weight = 1 / N                  # Model weight for each system models\n",
    "    return sum(partial_total_order_variance(Alpha[i, :], A[i, :]) * model_weight for i in range(N)) / multi_model_total_variance(Alpha, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the parameters used in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three processes (or product elements) are considered here and each of which can be simulated by two alternative process models\n",
    "delta = np.array([0, 0, 0])\n",
    "\n",
    "alpha = np.array([[1,  2], [1, 2], [1, 2]])\n",
    "a = np.array([[1.5, 1.2], [4.2, 1.8], [6.5, 2.3]])\n",
    "\n",
    "# Generate the parameter combinations for the 8 system models\n",
    "Alpha = np.array(list(itertools.product(* alpha)))\n",
    "A = np.array(list(itertools.product(* a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the analytical parameter sensitity index for individual model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tA1B1C1\t\t\tA1B1C2\t\t\tA1B2C1\t\t\tA1B2C2\n",
      "Para.\tx1\tx2\tx3\tx1\tx2\tx3\tx1\tx2\tx3\tx1\tx2\tx3\n",
      "S1\t73.42\t16.97\t8.16\t36.87\t8.52\t50.79\t31.80\t60.85\t3.53\t21.67\t41.46\t29.85\n",
      "ST\t74.77\t17.98\t8.70\t40.07\t9.64\t54.15\t35.26\t64.47\t4.10\t25.64\t46.88\t34.65\n",
      "Model\tA2B1C1\t\t\tA2B1C2\t\t\tA2B2C1\t\t\tA2B2C2\n",
      "Para.\tx1\tx2\tx3\tx1\tx2\tx3\tx1\tx2\tx3\tx1\tx2\tx3\n",
      "S1\t88.56\t6.60\t3.17\t62.07\t4.63\t27.58\t56.64\t34.97\t2.03\t43.67\t26.96\t19.41\n",
      "ST\t90.18\t7.74\t3.75\t67.45\t5.79\t32.54\t62.79\t40.99\t2.61\t51.66\t33.72\t24.92\n"
     ]
    }
   ],
   "source": [
    "theoretical_S1 = np.zeros([8, 3])\n",
    "theoretical_ST = np.zeros([8, 3])\n",
    "for i in range(8):\n",
    "    theoretical_S1[i, :] = first_order_parameter_sensitivity_index(Alpha[i, :], A[i, :])\n",
    "    theoretical_ST[i, :] = total_parameter_sensitivity_index(Alpha[i, :], A[i, :])\n",
    "    \n",
    "print('Model\\tA1B1C1\\t\\t\\tA1B1C2\\t\\t\\tA1B2C1\\t\\t\\tA1B2C2')\n",
    "print('Para.\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3')\n",
    "print('S1\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f' %(theoretical_S1[0, 0] * 100, theoretical_S1[0, 1] * 100, theoretical_S1[0, 2] * 100, theoretical_S1[1, 0] * 100, theoretical_S1[1, 1] * 100, theoretical_S1[1, 2] * 100, theoretical_S1[2, 0] * 100, theoretical_S1[2, 1] * 100, theoretical_S1[2, 2] * 100, theoretical_S1[3, 0] * 100, theoretical_S1[3, 1] * 100, theoretical_S1[3, 2] * 100))\n",
    "print('ST\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f' %(theoretical_ST[0, 0] * 100, theoretical_ST[0, 1] * 100, theoretical_ST[0, 2] * 100, theoretical_ST[1, 0] * 100, theoretical_ST[1, 1] * 100, theoretical_ST[1, 2] * 100, theoretical_ST[2, 0] * 100, theoretical_ST[2, 1] * 100, theoretical_ST[2, 2] * 100, theoretical_ST[3, 0] * 100, theoretical_ST[3, 1] * 100, theoretical_ST[3, 2] * 100))\n",
    "\n",
    "print('Model\\tA2B1C1\\t\\t\\tA2B1C2\\t\\t\\tA2B2C1\\t\\t\\tA2B2C2')\n",
    "print('Para.\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3')\n",
    "print('S1\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f' %(theoretical_S1[4, 0] * 100, theoretical_S1[4, 1] * 100, theoretical_S1[4, 2] * 100, theoretical_S1[5, 0] * 100, theoretical_S1[5, 1] * 100, theoretical_S1[5, 2] * 100, theoretical_S1[6, 0] * 100, theoretical_S1[6, 1] * 100, theoretical_S1[6, 2] * 100, theoretical_S1[7, 0] * 100, theoretical_S1[7, 1] * 100, theoretical_S1[7, 2] * 100))\n",
    "print('ST\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f' %(theoretical_ST[4, 0] * 100, theoretical_ST[4, 1] * 100, theoretical_ST[4, 2] * 100, theoretical_ST[5, 0] * 100, theoretical_ST[5, 1] * 100, theoretical_ST[5, 2] * 100, theoretical_ST[6, 0] * 100, theoretical_ST[6, 1] * 100, theoretical_ST[6, 2] * 100, theoretical_ST[7, 0] * 100, theoretical_ST[7, 1] * 100, theoretical_ST[7, 2] * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the analytical process sensitivity index considering process model uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process\tA\tB\tC\n",
      "PS1\t49.85\t26.08\t18.10\n",
      "PST\t54.79\t30.07\t21.23\n"
     ]
    }
   ],
   "source": [
    "print('Process\\tA\\tB\\tC')\n",
    "print('PS1\\t%.2f\\t%.2f\\t%.2f' %(first_order_process_sensitivity_index(alpha, a)[0] * 100, first_order_process_sensitivity_index(alpha, a)[1] * 100, first_order_process_sensitivity_index(alpha, a)[2] * 100))\n",
    "print('PST\\t%.2f\\t%.2f\\t%.2f' %(total_order_process_sensitivity_index(Alpha, A)[0] * 100, total_order_process_sensitivity_index(Alpha, A)[1] * 100, total_order_process_sensitivity_index(Alpha, A)[2] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MC-based sensitivity index for each system model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first-order and total parameter sensitivity index values for the individual system model are calculated using SALib - Sensitivity Analysis Library in Python. The package can be freely downloaded from https://salib.readthedocs.io/en/latest/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model inputs\n",
    "problem = {'num_vars': 3,\n",
    "           'names': ['x1', 'x2', 'x3'],\n",
    "           'bounds': [[0, 1], [0, 1], [0, 1]],\n",
    "           'dists': ['unif', 'unif', 'unif']         \n",
    "           }      \n",
    "\n",
    "# Generate parameters           \n",
    "param_values = saltelli.sample(problem, 40000, calc_second_order=False, seed=2**30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tA1B1C1\t\t\tA1B1C2\t\t\tA1B2C1\t\t\tA1B2C2\n",
      "Para.\tx1\tx2\tx3\tx1\tx2\tx3\tx1\tx2\tx3\tx1\tx2\tx3\n",
      "S1\t73.43\t16.97\t8.16\t36.87\t8.52\t50.78\t31.81\t60.85\t3.53\t21.66\t41.47\t29.86\n",
      "ST\t74.74\t17.99\t8.70\t40.03\t9.64\t54.16\t35.23\t64.49\t4.11\t25.59\t46.89\t34.67\n",
      "Model\tA2B1C1\t\t\tA2B1C2\t\t\tA2B2C1\t\t\tA2B2C2\n",
      "Para.\tx1\tx2\tx3\tx1\tx2\tx3\tx1\tx2\tx3\tx1\tx2\tx3\n",
      "S1\t88.55\t6.61\t3.17\t62.05\t4.64\t27.57\t56.65\t34.97\t2.02\t43.63\t26.98\t19.39\n",
      "ST\t90.15\t7.74\t3.75\t67.40\t5.79\t32.54\t62.75\t40.99\t2.61\t51.57\t33.72\t24.95\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "analytical_S1 = np.zeros([8, 3])\n",
    "analytical_ST = np.zeros([8, 3])\n",
    "for i in range(8):\n",
    "    Y = evaluate(param_values, delta, Alpha[i, :], A[i, :])\n",
    "\n",
    "    # Perform analysis\n",
    "    sobol_Si = sobol.analyze(problem, Y, conf_level=0.95, print_to_console=False, calc_second_order=False)\n",
    "    \n",
    "    analytical_S1[i, :] = sobol_Si['S1']\n",
    "    analytical_ST[i, :] = sobol_Si['ST']\n",
    "\n",
    "print('Model\\tA1B1C1\\t\\t\\tA1B1C2\\t\\t\\tA1B2C1\\t\\t\\tA1B2C2')\n",
    "print('Para.\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3')\n",
    "print('S1\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f' %(analytical_S1[0, 0] * 100, analytical_S1[0, 1] * 100, analytical_S1[0, 2] * 100, analytical_S1[1, 0] * 100, analytical_S1[1, 1] * 100, analytical_S1[1, 2] * 100, analytical_S1[2, 0] * 100, analytical_S1[2, 1] * 100, analytical_S1[2, 2] * 100, analytical_S1[3, 0] * 100, analytical_S1[3, 1] * 100, analytical_S1[3, 2] * 100))\n",
    "print('ST\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f' %(analytical_ST[0, 0] * 100, analytical_ST[0, 1] * 100, analytical_ST[0, 2] * 100, analytical_ST[1, 0] * 100, analytical_ST[1, 1] * 100, analytical_ST[1, 2] * 100, analytical_ST[2, 0] * 100, analytical_ST[2, 1] * 100, analytical_ST[2, 2] * 100, analytical_ST[3, 0] * 100, analytical_ST[3, 1] * 100, analytical_ST[3, 2] * 100))\n",
    "\n",
    "print('Model\\tA2B1C1\\t\\t\\tA2B1C2\\t\\t\\tA2B2C1\\t\\t\\tA2B2C2')\n",
    "print('Para.\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3\\tx1\\tx2\\tx3')\n",
    "print('S1\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f' %(analytical_S1[4, 0] * 100, analytical_S1[4, 1] * 100, analytical_S1[4, 2] * 100, analytical_S1[5, 0] * 100, analytical_S1[5, 1] * 100, analytical_S1[5, 2] * 100, analytical_S1[6, 0] * 100, analytical_S1[6, 1] * 100, analytical_S1[6, 2] * 100, analytical_S1[7, 0] * 100, analytical_S1[7, 1] * 100, analytical_S1[7, 2] * 100))\n",
    "print('ST\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f' %(analytical_ST[4, 0] * 100, analytical_ST[4, 1] * 100, analytical_ST[4, 2] * 100, analytical_ST[5, 0] * 100, analytical_ST[5, 1] * 100, analytical_ST[5, 2] * 100, analytical_ST[6, 0] * 100, analytical_ST[6, 1] * 100, analytical_ST[6, 2] * 100, analytical_ST[7, 0] * 100, analytical_ST[7, 1] * 100, analytical_ST[7, 2] * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the ouput considering both model uncertainty and parmateric uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numba\\np\\ufunc\\parallel.py:355: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 10005. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "# Model information\n",
    "N = 800                # Number of samples generated for each  parameter\n",
    "Ma = 2                 # Number of alterantive models for recharge process\n",
    "Mb = 2                 # Number of alterantive models for geloogy process\n",
    "Mc = 2                 # Number of alterantive models for snow melt process\n",
    "\n",
    "# Generate parameters using SALib.sample.saltelli\n",
    "problem = {'num_vars': 3,\n",
    "           'names': ['x1', 'x2', 'x3'],\n",
    "           'bounds': [[0, 1], [0, 1], [0, 1]],\n",
    "           'dists': ['unif', 'unif', 'unif']         \n",
    "           }    \n",
    "\n",
    "param_values = saltelli.sample(problem, N, calc_second_order=False, seed=2**30)[::5, :]\n",
    "\n",
    "# Calculate system output using numba to accelerate\n",
    "@nb.njit(parallel=True, fastmath=True)\n",
    "def cmpt_Dscs():\n",
    "    sims = 0\n",
    "    Y = np.zeros((Ma, N, Mb, N, Mc, N), dtype=np.float32)\n",
    "    \n",
    "    for i in range(Ma):\n",
    "        for j in nb.prange(N):\n",
    "            if i == 0:\n",
    "                alpha1 = alpha[0, 0]\n",
    "                a1 = a[0, 0]\n",
    "                values = param_values[j, 0]\n",
    "                g1 = ((1 + alpha1) * np.power(np.abs(2 * values - 1), alpha1) + a1) / (1 + a1)\n",
    "            else:\n",
    "                alpha1 = alpha[0, 1]\n",
    "                a1 = a[0, 1]\n",
    "                values = param_values[j, 0]\n",
    "                g1 = ((1 + alpha1) * np.power(np.abs(2 * values - 1), alpha1) + a1) / (1 + a1)\n",
    "                \n",
    "            for k in range (Mb):\n",
    "                for l in nb.prange(N):\n",
    "                    if k == 0:\n",
    "                        alpha2 = alpha[1, 0]\n",
    "                        a2 = a[1, 0]\n",
    "                        values = param_values[l, 1]\n",
    "                        g2 = ((1 + alpha2) * np.power(np.abs(2 * values - 1), alpha2) + a2) / (1 + a2)\n",
    "                    else:\n",
    "                        alpha2 = alpha[1, 1]\n",
    "                        a2 = a[1, 1]\n",
    "                        values = param_values[l, 1]\n",
    "                        g2 = ((1 + alpha2) * np.power(np.abs(2 * values - 1), alpha2) + a2) / (1 + a2)\n",
    "                        \n",
    "                    for m in range(Mc):\n",
    "                        for n in nb.prange(N):\n",
    "                            if m == 0:\n",
    "                                alpha3 = alpha[2, 0]\n",
    "                                a3 = a[2, 0]\n",
    "                                values = param_values[n, 2]\n",
    "                                g3 = ((1 + alpha3) * np.power(np.abs(2 * values - 1), alpha3) + a3) / (1 + a3)\n",
    "                            else:\n",
    "                                alpha3 = alpha[2, 1]\n",
    "                                a3 = a[2, 1]\n",
    "                                values = param_values[n, 2]\n",
    "                                g3 = ((1 + alpha3) * np.power(np.abs(2 * values - 1), alpha3) + a3) / (1 + a3)\n",
    "                            \n",
    "                            sims = sims + 1\n",
    "                            '''\n",
    "                            # If parallel computing is used, do not print info \n",
    "                            if sims % (N * Mc * N) == 0 :\n",
    "                                print('Evaluating dvds at i =', i, 'j =', j, 'k =' , k, 'l =', l, 'm =', m, 'n =', n)\n",
    "                            '''\n",
    "                            Y[i, j, k, l, m, n] = g1 * g2 * g3\n",
    "                            \n",
    "    return Y\n",
    "                \n",
    "# Save results to local disk\n",
    "Y = cmpt_Dscs()\n",
    "np.save('Y_Sobol_G_' + str(N) + '.npy', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-order process sensitivit index for g1 process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firsd-order process sensitivity index for Process g1 is 0.4985\n"
     ]
    }
   ],
   "source": [
    "# @nb.jit(fastmath=True)\n",
    "def SI_Process_A(Y):\n",
    "    \n",
    "    Ma = 2\n",
    "    Mb = 2\n",
    "    Mc = 2\n",
    "    \n",
    "    PMA = np.array([0.5, 0.5])\n",
    "    PMB = np.array([0.5, 0.5])\n",
    "    PMC = np.array([0.5, 0.5])\n",
    "    \n",
    "    Var_t_d = np.var(Y)\n",
    "    \n",
    "    E_tc_d = np.zeros((Ma, N, Mb, N, Mc))\n",
    "    E_c_d = np.zeros((Ma, N, Mb, N))\n",
    "    E_tb_d = np.zeros((Ma, N, Mb))\n",
    "    E_b_d = np.zeros((Ma, N))\n",
    "    E_ta_d = np.zeros(Ma)\n",
    "    E_ta_d2 = np.zeros(Ma)\n",
    "     \n",
    "    for i in range(Ma):      \n",
    "        for j in range(N):                \n",
    "            for k in range(Mb):    \n",
    "                for l in range(N):                 \n",
    "                    for m in range(Mc):\n",
    "                        E_tc_d[i, j, k, l, m] = np.mean(Y[i, j, k, l, m, :])\n",
    "                    E_c_d[i, j, k, l] = PMC[0] * E_tc_d[i, j, k, l, 0] + PMC[1] * E_tc_d[i, j, k, l, 1]\n",
    "                E_tb_d[i, j, k] = np.mean(E_c_d[i, j, k, :])\n",
    "            E_b_d[i, j] = PMB[0] * E_tb_d[i, j, 0] + PMB[1] * E_tb_d[i, j, 1]\n",
    "        E_ta_d[i] = np.mean(E_b_d[i, :])\n",
    "        E_ta_d2[i] = np.mean(E_b_d[i, :]**2)\n",
    "        \n",
    "    E_a_d = PMA[0] * E_ta_d[0] + PMA[1] * E_ta_d[1]\n",
    "    E_a_d2 = PMA[0] * E_ta_d2[0] + PMA[1] * E_ta_d2[1]\n",
    " \n",
    "    Var_A = E_a_d2 - E_a_d**2\n",
    "    SI_A = Var_A / (Var_t_d)\n",
    " \n",
    "    return SI_A, E_b_d\n",
    "   \n",
    "SI_A, E_b_d = SI_Process_A(Y)\n",
    "\n",
    "print('Firsd-order process sensitivity index for Process g1 is %.4f' %SI_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-order process sensitivit index for g2 process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firsd-order process sensitivity index for Process g2 is 0.2609\n"
     ]
    }
   ],
   "source": [
    "# @nb.jit(fastmath=True)\n",
    "def SI_Process_B(Y):\n",
    "   \n",
    "    Ma = 2\n",
    "    Mb = 2\n",
    "    Mc = 2\n",
    "    \n",
    "    PMA = np.array([0.5, 0.5])\n",
    "    PMB = np.array([0.5, 0.5])\n",
    "    PMC = np.array([0.5, 0.5])\n",
    "    \n",
    "    Var_t_d = np.var(Y)\n",
    "    \n",
    "    E_tc_d = np.zeros([Mb, N, Ma, N, Mc])\n",
    "    E_c_d = np.zeros([Mb, N, Ma, N])\n",
    "    E_ta_d = np.zeros([Mb, N, Ma])\n",
    "    E_a_d = np.zeros([Mb, N])\n",
    "    E_tb_d = np.zeros([Mb])\n",
    "    E_tb_d2 = np.zeros([Mb])\n",
    "     \n",
    "    for i in range(Mb):      \n",
    "        for j in range(N):                \n",
    "            for k in range(Ma):    \n",
    "                for l in range(N):                 \n",
    "                    for m in range(Mc):\n",
    "                        E_tc_d[i, j, k, l, m] = np.mean(Y[k, l, i, j, m, :])\n",
    "                    E_c_d[i, j, k, l] = PMC[0] * E_tc_d[i, j, k, l, 0] + PMC[1] * E_tc_d[i, j, k, l, 1]\n",
    "                E_ta_d[i, j, k] = np.mean(E_c_d[i, j, k, :])\n",
    "            E_a_d[i, j] = PMA[0] * E_ta_d[i, j, 0] + PMA[1] * E_ta_d[i, j, 1]\n",
    "        E_tb_d[i] = np.mean(E_a_d[i, :])\n",
    "        E_tb_d2[i] = np.mean(E_a_d[i, :]**2)\n",
    "        \n",
    "    E_b_d = PMB[0] * E_tb_d[0] + PMB[1] * E_tb_d[1]\n",
    "    E_b_d2 = PMB[0] * E_tb_d2[0] + PMB[1] * E_tb_d2[1]\n",
    "\n",
    "    Var_B = E_b_d2 - E_b_d**2\n",
    "    SI_B = Var_B / (Var_t_d)\n",
    " \n",
    "    return SI_B, E_a_d\n",
    "   \n",
    "SI_B, E_a_d = SI_Process_B(Y)\n",
    "\n",
    "print('Firsd-order process sensitivity index for Process g2 is %.4f' %SI_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-order process sensitivit index for g3 process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firsd-order process sensitivity index for Process g3 is 0.1807\n"
     ]
    }
   ],
   "source": [
    "# @nb.jit(fastmath=True)\n",
    "def SI_Process_C(Y):\n",
    "    \n",
    "    Ma = 2\n",
    "    Mb = 2\n",
    "    Mc = 2\n",
    "    \n",
    "    PMA = np.array([0.5, 0.5])\n",
    "    PMB = np.array([0.5, 0.5])\n",
    "    PMC = np.array([0.5, 0.5])\n",
    "    \n",
    "    Var_t_d = np.var(Y)\n",
    "    \n",
    "    E_tb_d = np.zeros([Mc, N, Ma, N, Mb])\n",
    "    E_b_d = np.zeros([Mc, N, Ma, N])\n",
    "    E_ta_d = np.zeros([Mc, N, Ma])\n",
    "    E_a_d = np.zeros([Mc, N])\n",
    "    E_tc_d = np.zeros([Mc])\n",
    "    E_tc_d2 = np.zeros([Mc])\n",
    "     \n",
    "    for i in range(Mc):      \n",
    "        for j in range(N):                \n",
    "            for k in range(Ma):    \n",
    "                for l in range(N):                 \n",
    "                    for m in range(Mb):\n",
    "                        E_tb_d[i, j, k, l, m] = np.mean(Y[k, l, m, :, i, j])\n",
    "                    E_b_d[i, j, k, l] = PMB[0] * E_tb_d[i, j, k, l, 0] + PMB[1] * E_tb_d[i, j, k, l, 1]\n",
    "                E_ta_d[i, j, k] = np.mean(E_b_d[i, j, k, :])\n",
    "            E_a_d[i, j] = PMA[0] * E_ta_d[i, j, 0] + PMA[1] * E_ta_d[i, j, 1]\n",
    "        E_tc_d[i] = np.mean(E_a_d[i, :])\n",
    "        E_tc_d2[i] = np.mean(E_a_d[i, :]**2)\n",
    "        \n",
    "    E_c_d = PMC[0] * E_tc_d[0] + PMC[1] * E_tc_d[1]\n",
    "    E_c_d2 = PMC[0] * E_tc_d2[0] + PMC[1] * E_tc_d2[1]\n",
    "\n",
    "    Var_C = E_c_d2 - E_c_d**2\n",
    "    SI_C = Var_C / (Var_t_d)\n",
    " \n",
    "    return SI_C, E_a_d\n",
    "   \n",
    "SI_C, E_c_d = SI_Process_C(Y)\n",
    "\n",
    "print('Firsd-order process sensitivity index for Process g3 is %.4f' %SI_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total process sensitivit index for g1 process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total process sensitivity index for Process g1 is 0.5480\n"
     ]
    }
   ],
   "source": [
    "# @nb.jit(fastmath=True)\n",
    "def ST_Process_A(Y):\n",
    "    \n",
    "    Ma = 2\n",
    "    Mb = 2\n",
    "    Mc = 2\n",
    "    \n",
    "    PMA = np.array([0.5, 0.5])\n",
    "    PMB = np.array([0.5, 0.5])\n",
    "    PMC = np.array([0.5, 0.5])\n",
    "    \n",
    "    Var_t_d = np.var(Y)\n",
    "    \n",
    "    E_ta_d = np.zeros([Mb, N, Mc, N, Ma])\n",
    "    E_a_d = np.zeros([Mb, N, Mc, N])\n",
    "    E_tc_d = np.zeros([Mb, N, Mc])\n",
    "    E_tc_d2 = np.zeros([Mb, N, Mc])\n",
    "    E_c_d = np.zeros([Mb, N])\n",
    "    E_c_d2 = np.zeros([Mb, N])\n",
    "\n",
    "    E_tb_d = np.zeros([Mb])\n",
    "    E_tb_d2 = np.zeros([Mb])\n",
    "    \n",
    "\n",
    "    for i in range(Mb):\n",
    "        for j in range(N):\n",
    "            for k in range(Mc):\n",
    "                for l in range(N):\n",
    "                    for m in range(Ma):\n",
    "                        E_ta_d[i, j, k, l, m] = np.mean(Y[m, :, i, j, k, l])\n",
    "                    E_a_d[i, j, k, l] = PMA[0] * np.mean(E_ta_d[i, j, k, l, 0]) + PMA[1] * np.mean(E_ta_d[i, j, k, l, 1])\n",
    "                E_tc_d[i, j, k] = np.mean(E_a_d[i, j, k, :])\n",
    "                E_tc_d2[i, j, k] = np.mean(E_a_d[i, j, k, :]**2)\n",
    "            E_c_d[i, j] = PMC[0] * E_tc_d[i, j, 0] + PMC[1] * E_tc_d[i, j, 1]\n",
    "            E_c_d2[i, j] = PMC[0] * E_tc_d2[i, j, 0] + PMC[1] * E_tc_d2[i, j, 1]\n",
    "        E_tb_d[i] = np.mean(E_c_d[i, :])\n",
    "        E_tb_d2[i] = np.mean(E_tc_d2[i, :])\n",
    "    E_b_d = PMB[0] * E_tb_d[0] + PMB[1] * E_tb_d[1]\n",
    "    E_b_d2 = PMB[0] * E_tb_d2[0] + PMB[1] * E_tb_d2[1]\n",
    "        \n",
    "    Var_A = E_b_d2 - E_b_d**2\n",
    "    ST_A = 1 - Var_A / (Var_t_d + 1e-20)\n",
    "    \n",
    "    return ST_A\n",
    "\n",
    "ST_A = ST_Process_A(Y)\n",
    "\n",
    "print('Total process sensitivity index for Process g1 is %.4f' %ST_A)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total process sensitivity index for g2 process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total process sensitivity index for Process g2 is 0.3009\n"
     ]
    }
   ],
   "source": [
    "# @nb.jit(fastmath=True)\n",
    "def ST_Process_B(Y):\n",
    "    \n",
    "    Ma = 2\n",
    "    Mb = 2\n",
    "    Mc = 2\n",
    "    \n",
    "    PMA = np.array([0.5, 0.5])\n",
    "    PMB = np.array([0.5, 0.5])\n",
    "    PMC = np.array([0.5, 0.5])\n",
    "    \n",
    "    Var_t_d = np.var(Y)\n",
    "    \n",
    "    E_tb_d = np.zeros([Ma, N, Mc, N, Mb])\n",
    "    E_b_d = np.zeros([Ma, N, Mc, N])\n",
    "    E_tc_d = np.zeros([Ma, N, Mc])\n",
    "    E_tc_d2 = np.zeros([Ma, N, Mc])\n",
    "    E_c_d = np.zeros([Ma, N])\n",
    "    E_c_d2 = np.zeros([Ma, N])\n",
    "\n",
    "    E_ta_d = np.zeros([Ma])\n",
    "    E_ta_d2 = np.zeros([Ma])\n",
    "    \n",
    "\n",
    "    for i in range(Ma):\n",
    "        for j in range(N):\n",
    "            for k in range(Mc):\n",
    "                for l in range(N):\n",
    "                    for m in range(Mb):\n",
    "                        E_tb_d[i, j, k, l, m] = np.mean(Y[i, j, m, :, k, l])\n",
    "                    E_b_d[i, j, k, l] = PMB[0] * np.mean(E_tb_d[i, j, k, l, 0]) + PMB[1] * np.mean(E_tb_d[i, j, k, l, 1])\n",
    "                E_tc_d[i, j, k] = np.mean(E_b_d[i, j, k, :])\n",
    "                E_tc_d2[i, j, k] = np.mean(E_b_d[i, j, k, :]**2)\n",
    "            E_c_d[i, j] = PMC[0] * E_tc_d[i, j, 0] + PMC[1] * E_tc_d[i, j, 1]\n",
    "            E_c_d2[i, j] = PMC[0] * E_tc_d2[i, j, 0] + PMC[1] * E_tc_d2[i, j, 1]\n",
    "        E_ta_d[i] = np.mean(E_c_d[i, :])\n",
    "        E_ta_d2[i] = np.mean(E_tc_d2[i, :])\n",
    "    E_a_d = PMA[0] * E_ta_d[0] + PMA[1] * E_ta_d[1]\n",
    "    E_a_d2 = PMA[0] * E_ta_d2[0] + PMA[1] * E_ta_d2[1]\n",
    "        \n",
    "    Var_B = E_a_d2 - E_a_d**2\n",
    "    ST_B = 1 - Var_B / (Var_t_d + 1e-20)\n",
    "    \n",
    "    return ST_B\n",
    "\n",
    "ST_B = ST_Process_B(Y)\n",
    "\n",
    "print('Total process sensitivity index for Process g2 is %.4f' %ST_B) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total process sensitivity index for snow-melt process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total process sensitivity index for Process g3 is 0.2120\n"
     ]
    }
   ],
   "source": [
    "# @nb.jit(fastmath=True)\n",
    "def ST_Process_C(Y):\n",
    "    \n",
    "    Ma = 2\n",
    "    Mb = 2\n",
    "    Mc = 2\n",
    "    \n",
    "    PMA = np.array([0.5, 0.5])\n",
    "    PMB = np.array([0.5, 0.5])\n",
    "    PMC = np.array([0.5, 0.5])\n",
    "    \n",
    "    Var_t_d = np.var(Y)\n",
    "    \n",
    "    E_tc_d = np.zeros([Ma, N, Mb, N, Mc])\n",
    "    E_c_d = np.zeros([Ma, N, Mb, N])\n",
    "    E_tb_d = np.zeros([Ma, N, Mb])\n",
    "    E_tb_d2 = np.zeros([Ma, N, Mb])\n",
    "    E_b_d = np.zeros([Ma, N])\n",
    "    E_b_d2 = np.zeros([Ma, N])\n",
    "\n",
    "    E_ta_d = np.zeros([Ma])\n",
    "    E_ta_d2 = np.zeros([Ma])\n",
    "    \n",
    "\n",
    "    for i in range(Ma):\n",
    "        for j in range(N):\n",
    "            for k in range(Mb):\n",
    "                for l in range(N):\n",
    "                    for m in range(Mc):\n",
    "                        E_tc_d[i, j, k, l, m] = np.mean(Y[i, j, k, l, m, :])\n",
    "                    E_c_d[i, j, k, l] = PMC[0] * np.mean(E_tc_d[i, j, k, l, 0]) + PMC[1] * np.mean(E_tc_d[i, j, k, l, 1])\n",
    "                E_tb_d[i, j, k] = np.mean(E_c_d[i, j, k, :])\n",
    "                E_tb_d2[i, j, k] = np.mean(E_c_d[i, j, k, :]**2)\n",
    "            E_b_d[i, j] = PMB[0] * E_tb_d[i, j, 0] + PMB[1] * E_tb_d[i, j, 1]\n",
    "            E_b_d2[i, j] = PMB[0] * E_tb_d2[i, j, 0] + PMB[1] * E_tb_d2[i, j, 1]\n",
    "        E_ta_d[i] = np.mean(E_b_d[i, :])\n",
    "        E_ta_d2[i] = np.mean(E_tb_d2[i, :])\n",
    "    E_a_d = PMA[0] * E_ta_d[0] + PMA[1] * E_ta_d[1]\n",
    "    E_a_d2 = PMA[0] * E_ta_d2[0] + PMA[1] * E_ta_d2[1]\n",
    "        \n",
    "    Var_C = E_a_d2 - E_a_d**2\n",
    "    ST_C = 1 - Var_C / (Var_t_d + 1e-20)\n",
    "    \n",
    "    return ST_C\n",
    "\n",
    "ST_C = ST_Process_C(Y)\n",
    "\n",
    "print('Total process sensitivity index for Process g3 is %.4f' %ST_C) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
